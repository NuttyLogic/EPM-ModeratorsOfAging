{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GEO 450k and EPIC Data Downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from ftplib import FTP\n",
    "import gzip\n",
    "import io\n",
    "import math\n",
    "import os \n",
    "import pickle\n",
    "import random\n",
    "import shutil\n",
    "import subprocess\n",
    "from typing import Dict, List, Union\n",
    "\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from GEODataProcessing.SeriesMatrixMetaExtractor import SeriesMatrixMetaExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = os.getcwd() + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = '/u/nobackup/mcdbscratch/colinpat/EPMTraitAssociation/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "four_50k_meta = f'{home_dir}450k_top_500.txt'\n",
    "epic_meta = f'{home_dir}epic_top_500.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_meta_data(file_path, platform_id):\n",
    "    with open(file_path, 'r') as meta:\n",
    "        all_exps = {}\n",
    "        exp_info = {}\n",
    "        for line in meta:\n",
    "            line_strip = line.strip()\n",
    "            if not line_strip:\n",
    "                if exp_info:\n",
    "                    all_exps[exp_info['accession_id']] = exp_info\n",
    "                exp_info = {}\n",
    "            else:\n",
    "                if not exp_info:\n",
    "                    exp_info['title'] = ' '.join(line_strip.split(' ')[1:])\n",
    "                elif '(Submitter supplied)' in line_strip:\n",
    "                    exp_info['description'] = line_strip.replace('(Submitter supplied) ', '')\n",
    "                elif 'Organism' in line_strip:\n",
    "                    exp_info['organism'] = line_strip.split(':')[1].strip()\n",
    "                elif 'Platform' in line_strip:\n",
    "                    line_split = line_strip.split(' ')\n",
    "                    exp_info['platform_id'] = platform_id\n",
    "                    exp_info['sample_number'] = int(line_split[-2])\n",
    "                elif 'FTP' in line_strip:\n",
    "                    exp_info['ftp_link'] = line_strip.split(' ')[-1]\n",
    "                elif 'Series' in line_strip:\n",
    "                    line_split = line_strip.split('\\t')\n",
    "                    exp_info['accession_id'] = line_strip.split(': ')[1].split('\\t')[0]\n",
    "    return all_exps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse File Metadata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_exp = parse_meta_data(four_50k_meta, 'GPL13534')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_exp.update(parse_meta_data(epic_meta, 'GPL21145'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FTP Walking Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_exp_info(exp):\n",
    "    file_links = {}\n",
    "    raw_url = exp['ftp_link']\n",
    "    processed_link = raw_url.replace('ftp://', '').split('/')[0]\n",
    "    exp_dir = '/'.join(raw_url.replace('ftp://', '').split('/')[1:])\n",
    "    ftp = FTP(processed_link)\n",
    "    ftp.login()\n",
    "    ftp.cwd(exp_dir)\n",
    "    directories = ftp.nlst()\n",
    "    for direct in directories:\n",
    "        ftp.cwd(direct)\n",
    "        files = ftp.nlst()\n",
    "        file_links[direct] = (ftp.pwd(), files)\n",
    "        ftp.cwd('..')\n",
    "    if 'suppl' in file_links:\n",
    "        if 'filelist.txt' in file_links['suppl'][1]:\n",
    "            ftp.cwd('suppl')\n",
    "            supp_lines = []\n",
    "            ftp.retrlines('RETR filelist.txt', supp_lines.append)\n",
    "            file_links['supplemental_files'] = supp_lines\n",
    "    ftp.close()\n",
    "    return exp['accession_id'], f'ftp://{processed_link}', file_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('idat_exp_meta.pkl'):\n",
    "    processed_links = joblib.Parallel(n_jobs=8, verbose=10)(joblib.delayed(retrieve_exp_info)(exp) for exp in all_exp.values())\n",
    "    for exp_id, ftp_head, links in processed_links:\n",
    "        all_exp[exp_id].update(links)\n",
    "        all_exp[exp_id]['ftp_head'] = ftp_head\n",
    "        \n",
    "    idat_exps = []\n",
    "    idat_sample_count = 0\n",
    "\n",
    "    for exp_id, exp in all_exp.items():\n",
    "        supp_files = exp.get('supplemental_files', [])\n",
    "        for file in supp_files:\n",
    "            if 'IDAT' in file.upper():\n",
    "                idat_exps.append(exp_id)\n",
    "                idat_sample_count += exp['sample_number']\n",
    "                break\n",
    "                \n",
    "    idat_exp_info = {key: value for key, value in all_exp.items() if key in idat_exps}\n",
    "    \n",
    "    with open('idat_exp_meta.pkl', 'wb') as out:\n",
    "        pickle.dump(idat_exp_info, out)\n",
    "        \n",
    "else:\n",
    "    with open('idat_exp_meta.pkl', 'rb') as info:\n",
    "        idat_exp_info = pickle.load(info)\n",
    "        idat_exps = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dowload series matrix files for files with IDAT files available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_output_dir = f'{wd}series_matrices/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_series_matrix(exp, output_directory):\n",
    "    matrix_head, files = exp.get('matrix', (None, None))\n",
    "    if not matrix_head:\n",
    "        return exp['accession_id']\n",
    "    else:\n",
    "        series_head = f'{exp[\"ftp_head\"]}/{matrix_head}/'\n",
    "        series_file = None\n",
    "        if len(files) == 1:\n",
    "            series_file = files[0]\n",
    "        else:\n",
    "            for file in files:\n",
    "                if exp['platform_id'].upper() in file.upper():\n",
    "                    series_file = file\n",
    "        if not series_file:\n",
    "            return exp['accession_id']\n",
    "        if os.path.exists(f'{output_directory}{series_file}'):\n",
    "            return 0\n",
    "        wget_command = ['wget', '-nd', '-P', \n",
    "                        output_directory, f'{series_head}{series_file}']\n",
    "        p = subprocess.Popen(args=wget_command)\n",
    "        p.wait()\n",
    "        if p.returncode:\n",
    "            return exp['accession_id']\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=32)]: Using backend LokyBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=32)]: Done   0 out of   0 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "download_status = joblib.Parallel(n_jobs=32, verbose=10)(joblib.delayed(download_series_matrix)\n",
    "                                                         (*[all_exp[exp], series_output_dir]) for exp in idat_exps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Series Matrices to Extract MetaData "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_meta(exp, series_directory):\n",
    "    matrix_head, files = exp.get('matrix', (None, None))\n",
    "    series_file = None\n",
    "    if len(files) == 1:\n",
    "        series_file = files[0]\n",
    "    else:\n",
    "        for file in files:\n",
    "            if exp['platform_id'].upper() in file.upper():\n",
    "                series_file = file\n",
    "    directory = series_directory if series_directory.endswith('/') else f'{series_directory}/'\n",
    "    series_path = f'{directory}{series_file}'\n",
    "    matrix_parser = SeriesMatrixMetaExtractor(series_matrix_path=series_path, sample_id='!Sample_geo_accession', phenotype_ids=['!Sample_characteristics_ch1'])\n",
    "    matrix_parser.get_meta_data()\n",
    "    return matrix_parser.phenotype_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(f'{wd}all_meta.pkl'):\n",
    "    exp_sample_meta = joblib.Parallel(n_jobs=8, verbose=10)(joblib.delayed(extract_meta)(*[exp, series_output_dir]) for exp in idat_exp_info.values())\n",
    "    all_meta = {}\n",
    "    for exp in exp_sample_meta:\n",
    "        all_meta.update(exp)\n",
    "    with open(f'{wd}all_meta.pkl', 'wb') as out:\n",
    "        pickle.dump(all_meta, out)\n",
    "else:\n",
    "    with open(f'{wd}all_meta.pkl', 'rb') as meta:\n",
    "        all_meta = pickle.load(meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Meta with File Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_idat_meta(gsm_id, gsm_info, supp_files):\n",
    "    idat_files = {}\n",
    "    for file in supp_files:\n",
    "        if gsm_id in file:\n",
    "            file_name, file_date = file.strip().split('\\t')[1:3] \n",
    "            if 'grn' in file_name.lower():\n",
    "                idat_files['Grn'] = file_name\n",
    "            elif 'red' in file_name.lower():\n",
    "                idat_files['Red'] = file_name\n",
    "            idat_files['idat_date'] = file_date\n",
    "            if len(idat_files) == 3:\n",
    "                break\n",
    "    return gsm_id, idat_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(f'{wd}idat_meta.pkl'):\n",
    "    sample_idat_links = joblib.Parallel(n_jobs=8, verbose=10)(joblib.delayed(get_sample_idat_meta)\n",
    "                                                              (*[gsm_id, gsm_info, idat_exp_info[gsm_info['experiment_id']]['supplemental_files']]) for gsm_id, gsm_info in all_meta.items())\n",
    "    idat_sample_meta = {}\n",
    "    for gsm_id, idat_links in sample_idat_links:\n",
    "        if len(idat_links) == 3:\n",
    "            sample_info = all_meta[gsm_id]\n",
    "            sample_info.update(idat_links)\n",
    "            idat_sample_meta[gsm_id] = sample_info\n",
    "    with open(f'{wd}idat_meta.pkl', 'wb') as out:\n",
    "        pickle.dump(idat_sample_meta, out)\n",
    "else:\n",
    "    with open(f'{wd}idat_meta.pkl', 'rb') as meta:\n",
    "        idat_sample_meta = pickle.load(meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Phenotype Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_for_age(gsm_meta: dict) -> bool:\n",
    "    for key in gsm_meta:\n",
    "        if 'age' in key.lower() and 'stage' not in key.lower():\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "idat_age_meta = {key:value for key, value in idat_sample_meta.items() if search_for_age(value)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "idat_age_exps = set(gsm_meta['experiment_id'] for gsm_meta in idat_age_meta.values())\n",
    "idat_exps = {key:value for key, value in idat_exp_info.items() if key in idat_age_exps}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually remove cancer related exps\n",
    "exps_to_drop = ['GSE131482', 'GSE68825', 'GSE60274', 'GSE104293', 'GSE92462', 'GSE69636', 'GSE69633', 'GSE96879',\n",
    "                'GSE132804', 'GSE72308', 'GSE157341', 'GSE101764', 'GSE72021', 'GSE108462', 'GSE72251', 'GSE72245', \n",
    "                'GSE88883', 'GSE111933', 'GSE133918',  'GSE132804', 'GSE72308', 'GSE157341', 'GSE101764', 'GSE72021',\n",
    "                'GSE108462', 'GSE72251', 'GSE72245', 'GSE88883', 'GSE111933', 'GSE133918', 'GSE104210', 'GSE104210',\n",
    "                'GSE93646', 'GSE60185', 'GSE77276', 'GSE49149', 'GSE66836', 'GSE103659', 'GSE89181', 'GSE73515',\n",
    "                'GSE86961', 'GSE128654', 'GSE89852', 'GSE85828', 'GSE131013', 'GSE141039', 'GSE70460', 'GSE97466', \n",
    "                'GSE141363', 'GSE68838', 'GSE122126', 'GSE77955', 'GSE118694', 'GSE155311', 'GSE116699', 'GSE146556','GSE146556',\n",
    " 'GSE100850',\n",
    " 'GSE130748',\n",
    " 'GSE133985',\n",
    " 'GSE144213',\n",
    " 'GSE149282',\n",
    " 'GSE116699',\n",
    " 'GSE119260',\n",
    " 'GSE123367',\n",
    "                'GSE122469', 'GSE158612', 'GSE14125', 'GSE136724', 'GSE110600', 'GSE103280', 'GSE103271', 'GSE103328', 'GSE94677'\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "idat_exps = {key: value for key, value in idat_exps.items() if key not in exps_to_drop and value['sample_number'] > 50}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "idat_sample_meta = {gsm_id: gsm_meta for gsm_id, gsm_meta in idat_sample_meta.items() if gsm_meta['experiment_id'] in idat_exps}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f749289e4ed5455dae4f01e470fb4bb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20707.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "age_cats = set()\n",
    "ages = []\n",
    "\n",
    "for gsm_id in tqdm(idat_sample_meta):\n",
    "    gsm_meta = dict(idat_sample_meta[gsm_id].items())\n",
    "    for cat, value in gsm_meta.items():\n",
    "        if 'age' in cat.lower() and 'stage' not in cat.lower():\n",
    "            if cat == 'age (days)':\n",
    "                idat_sample_meta[gsm_id]['age yrs'] = float(value) / 365\n",
    "                continue\n",
    "            if cat == 'fetal gestational age (weeks)':\n",
    "                idat_sample_meta[gsm_id]['age yrs'] = float(value) / 52\n",
    "                continue\n",
    "            if gsm_meta['experiment_id'] == 'GSE67444':\n",
    "                continue\n",
    "            age_cats.add(cat)\n",
    "            try:\n",
    "                idat_sample_meta[gsm_id]['age yrs'] = float(value)\n",
    "                ages.append(float(value))\n",
    "            except ValueError:\n",
    "                pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21286"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "\n",
    "sns.histplot(ages, kde=False, ax=ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download IDAT Files for all samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "idat_directory = f'{wd}idat_files/'\n",
    "temp_dir = f'{wd}temp/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for exp, exp_meta in idat_exps.items():\n",
    "    good = False\n",
    "    for file in exp_meta['suppl'][1]:\n",
    "        if 'RAW' in file:\n",
    "            good = True\n",
    "    if not good:\n",
    "        print(exp, exp_meta['suppl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_file(exp_meta):\n",
    "    for file in exp_meta['suppl'][1]:\n",
    "        if 'RAW' in file:\n",
    "            return file\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_extract_idats(exp, temp_head, output_directory):\n",
    "    suppl_head, files = exp.get('suppl', (None, None))\n",
    "    suppl_file = get_raw_file(exp)\n",
    "    if not suppl_file:\n",
    "        return exp['accession_id']\n",
    "    else:\n",
    "        suppl_path = f'{exp[\"ftp_head\"]}/{suppl_head}/{suppl_file}'\n",
    "        temp_directory = f'{temp_head}{exp[\"accession_id\"]}/'\n",
    "        try:\n",
    "            os.mkdir(temp_directory)\n",
    "        except FileExistsError:\n",
    "            return exp['accession_id']\n",
    "        wget_command = ['wget', '-nd', '-P', \n",
    "                        temp_directory, suppl_path]\n",
    "        subprocess.Popen(['mkdir', '-p', ])\n",
    "        p_1 = subprocess.Popen(args=wget_command)\n",
    "        p_1.wait()\n",
    "        p_2 = subprocess.Popen(['tar', '-C', temp_directory, '-xvf', f'{temp_directory}{suppl_file}'])\n",
    "        p_2.wait()\n",
    "        for head, directory, files in os.walk(temp_directory):\n",
    "            for file in files:\n",
    "                if 'idat' in file.lower():\n",
    "                    shutil.move(f'{head}/{file}', f'{output_directory}{file}')\n",
    "                else:\n",
    "                    os.remove(f'{head}/{file}')\n",
    "        os.rmdir(temp_directory)\n",
    "        if p_1.returncode or p_2.returncode:\n",
    "            return exp['accession_id']\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "download_status = joblib.Parallel(n_jobs=32, verbose=10)(joblib.delayed(download_and_extract_idats)\n",
    "                                                         (*[idat_exps[exp], temp_dir, idat_directory]) for exp in idat_exps)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check idat sample info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_idat_files(gsm_meta, idat_directory):\n",
    "    idat_files = [os.path.exists(f'{idat_directory}{gsm_meta[\"Grn\"]}'),\n",
    "                  os.path.exists(f'{idat_directory}{gsm_meta[\"Red\"]}')]\n",
    "    if not all(idat_files):\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sample_meta = {gsm_id: gsm_meta for gsm_id, gsm_meta \n",
    "                   in idat_sample_meta.items() if not check_idat_files(gsm_meta, idat_directory)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process IDAT Files\n",
    "- all samples are 450k \n",
    "- process as expermental groups with reference samples attached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_exps = set([sample['experiment_id'] for sample in all_sample_meta.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_samples(samples: List[str], batch_size: int = 100) -> List[List[str]]:\n",
    "        \"\"\"Generate sample batches\"\"\"\n",
    "        batches = []\n",
    "        batch_size = int(batch_size)\n",
    "        batch_number = int(len(samples) / batch_size)\n",
    "        if not batch_number:\n",
    "            batch_number = 1\n",
    "        batch_remainder = len(samples) % batch_size\n",
    "        if float(batch_remainder) / batch_size <= .6 and batch_remainder != 0:\n",
    "            batch_addition = int(batch_remainder / batch_number)\n",
    "            batch_size += batch_addition + 1\n",
    "            print(f'Adjusting batch size, new batch size = {batch_size}')\n",
    "        start, end = 0, batch_size\n",
    "        while True:\n",
    "            batch = samples[start: end]\n",
    "            if not batch:\n",
    "                break\n",
    "            batches.append(batch)\n",
    "            start += batch_size\n",
    "            end += batch_size\n",
    "        return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.333333333333334"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 / 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting batch size, new batch size = 15\n",
      "Adjusting batch size, new batch size = 19\n",
      "Adjusting batch size, new batch size = 21\n",
      "Adjusting batch size, new batch size = 13\n",
      "Adjusting batch size, new batch size = 13\n",
      "Adjusting batch size, new batch size = 17\n",
      "Adjusting batch size, new batch size = 16\n",
      "Adjusting batch size, new batch size = 13\n",
      "Adjusting batch size, new batch size = 25\n",
      "Adjusting batch size, new batch size = 17\n",
      "Adjusting batch size, new batch size = 13\n",
      "Adjusting batch size, new batch size = 17\n",
      "Adjusting batch size, new batch size = 20\n",
      "Adjusting batch size, new batch size = 19\n",
      "Adjusting batch size, new batch size = 21\n",
      "Adjusting batch size, new batch size = 16\n",
      "Adjusting batch size, new batch size = 19\n",
      "Adjusting batch size, new batch size = 18\n",
      "Adjusting batch size, new batch size = 14\n",
      "Adjusting batch size, new batch size = 16\n",
      "Adjusting batch size, new batch size = 17\n",
      "Adjusting batch size, new batch size = 25\n",
      "Adjusting batch size, new batch size = 26\n",
      "Adjusting batch size, new batch size = 20\n",
      "Adjusting batch size, new batch size = 18\n",
      "Adjusting batch size, new batch size = 22\n",
      "Adjusting batch size, new batch size = 20\n",
      "Adjusting batch size, new batch size = 14\n",
      "Adjusting batch size, new batch size = 20\n",
      "Adjusting batch size, new batch size = 19\n",
      "Adjusting batch size, new batch size = 17\n",
      "Adjusting batch size, new batch size = 15\n",
      "Adjusting batch size, new batch size = 19\n",
      "Adjusting batch size, new batch size = 24\n",
      "Adjusting batch size, new batch size = 26\n",
      "Adjusting batch size, new batch size = 15\n",
      "Adjusting batch size, new batch size = 23\n",
      "Adjusting batch size, new batch size = 18\n",
      "Adjusting batch size, new batch size = 19\n",
      "Adjusting batch size, new batch size = 21\n",
      "Adjusting batch size, new batch size = 15\n",
      "Adjusting batch size, new batch size = 14\n",
      "Adjusting batch size, new batch size = 23\n",
      "Adjusting batch size, new batch size = 19\n",
      "Adjusting batch size, new batch size = 16\n",
      "Adjusting batch size, new batch size = 26\n",
      "Adjusting batch size, new batch size = 16\n",
      "Adjusting batch size, new batch size = 15\n"
     ]
    }
   ],
   "source": [
    "processing_batches = {}\n",
    "\n",
    "for exp in process_exps:\n",
    "    exp_samples = []\n",
    "    for gsm_info in all_sample_meta.values():\n",
    "        if gsm_info['experiment_id'] == exp:\n",
    "            exp_samples.append(gsm_info['Red'].replace('_Red.idat.gz', ''))\n",
    "    chip_ids = Counter([sample.split('_')[1] for sample in exp_samples])\n",
    "    chip_size = math.ceil(np.mean(list(chip_ids.values())))\n",
    "    chip_ids = list(chip_ids.keys())\n",
    "    batch_size = 16 if abs(chip_size - 8) <= 1 else 12\n",
    "    exp_batches = batch_samples(chip_ids, batch_size)\n",
    "    initial_batches = []\n",
    "    for count, batch in enumerate(exp_batches):\n",
    "        batch_exp_samples = []\n",
    "        for sample in exp_samples:\n",
    "            if sample.split('_')[1] in batch:\n",
    "                batch_exp_samples.append(sample)\n",
    "        initial_batches.append(batch_exp_samples)\n",
    "        processing_batches[f'{exp}_{count + 1}'] = batch_exp_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "for batch, samples in processing_batches.items():\n",
    "    with open(f'ProcessExpsRefs/{batch}.txt', 'w') as out:\n",
    "        out.write('\\n'.join(samples))\n",
    "        \n",
    "with open(f'ref_sheets.txt', 'w') as out:\n",
    "    out.write('\\n'.join(list(processing_batches.keys()) + ['']))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_processing_batches = {}\n",
    "\n",
    "for exp in processing_batches:\n",
    "    with open(f'ProcessExpsRefs/{exp}.txt', 'r') as batch:\n",
    "        batch_samples = []\n",
    "        for sample in batch:\n",
    "            batch_samples.append(sample.strip())\n",
    "        cleaned_processing_batches[exp] = batch_samples\n",
    "        \n",
    "processing_batches = cleaned_processing_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_order = []\n",
    "\n",
    "with open('ref_sheets.txt', 'r') as ref:\n",
    "    for line in ref:\n",
    "        batch_order.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_batches = {batch: processing_batches[batch] for batch in batch_order}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse Processed Data and Update Sample Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dir = f'{wd}processed_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_gzip(file_path: str, yield_indices: Union[List[int], None] = None):\n",
    "    with io.BufferedReader(gzip.open(file_path, 'rb')) as file:\n",
    "        for line in file:\n",
    "            d_line = line.decode('utf-8').strip()\n",
    "            y_line = d_line.replace('\"', '').split(',')\n",
    "            if not yield_indices:\n",
    "                yield y_line\n",
    "            else:\n",
    "                yield [y_line[index] for index in yield_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_float(value):\n",
    "    try:\n",
    "        return float(value)\n",
    "    except ValueError:\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meta_data(file_path) -> dict:\n",
    "    header = None\n",
    "    meta_data = {}\n",
    "    for line in open_gzip(file_path):\n",
    "        if not header:\n",
    "            header = line[1:]\n",
    "        else:\n",
    "            sample = line[0].split('_')[0]\n",
    "            meta_data[sample] = {f'proc_{key}':convert_to_float(value) for key, value in zip(header, line[1:])}\n",
    "    return meta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "unprocessed_batches = [batch for batch in processing_batches if not os.path.exists(f'{processed_dir}{batch}_qc.gz')]\n",
    "unprocessed_exps = set([batch.split('_')[0] for batch in unprocessed_batches])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GSE144910_1 27 True GPL21145\n",
      "GSE144910_2 28 True GPL21145\n",
      "GSE144910_3 29 True GPL21145\n",
      "GSE144910_4 30 True GPL21145\n",
      "GSE144910_5 31 True GPL21145\n",
      "GSE144910_6 32 True GPL21145\n",
      "GSE144910_7 33 True GPL21145\n",
      "GSE117130_1 117 True GPL21145\n",
      "GSE117130_2 118 True GPL21145\n",
      "GSE136296_1 128 True GPL21145\n"
     ]
    }
   ],
   "source": [
    "# check to see whole experiments throwing errors and not just individual batches\n",
    "\n",
    "for count, batch in enumerate(processing_batches):\n",
    "    if batch.split('_')[0] in unprocessed_exps:\n",
    "        print(batch, count + 1, batch in unprocessed_batches, idat_exps[batch.split('_')[0]]['platform_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sample_meta = {sample:sample_info for sample, sample_info in all_sample_meta.items() if sample_info['experiment_id'] not in unprocessed_exps}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19dcbea555574ccd9f3c272efd1c1f8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=199.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ref_sample_meta = []\n",
    "\n",
    "for exp in tqdm(processing_batches):\n",
    "    if exp in unprocessed_batches:\n",
    "        continue\n",
    "    exp_id, batch = exp.split('_')\n",
    "    qc_meta = get_meta_data(f'{processed_dir}{exp}_qc.gz')\n",
    "    cell_meta = get_meta_data(f'{processed_dir}{exp}_cell_counts.gz')\n",
    "    for sample in qc_meta:\n",
    "        sample_qc = qc_meta[sample]\n",
    "        proc_qc_fail = 0\n",
    "        if sample_qc['proc_mMed'] < 10.0 or sample_qc['proc_mMed'] < 10.0:\n",
    "            proc_qc_fail = 1\n",
    "        all_sample_meta[sample]['proc_qc_fail'] = proc_qc_fail\n",
    "        all_sample_meta[sample]['batch'] = batch\n",
    "        all_sample_meta[sample].update(sample_qc)\n",
    "        all_sample_meta[sample].update(cell_meta[sample])\n",
    "        all_sample_meta[sample]['processing_complete'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_meta = {sample:sample_info for sample, sample_info in all_sample_meta.items() if 'processing_complete' in sample_info}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(f'{wd}processed_sample_meta.pkl'):\n",
    "    with open(f'{wd}processed_sample_meta.pkl', 'wb') as out:\n",
    "        pickle.dump(sample_meta, out)\n",
    "    with open(f'{wd}processed_ref_meta.pkl', 'wb') as out:\n",
    "        pickle.dump(ref_sample_meta, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
